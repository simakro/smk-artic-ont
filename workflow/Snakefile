# The main entry point of your workflow.
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.
import os

report: "report/workflow.rst"

# Allow users to fix the underlying OS via singularity.
singularity: "docker://continuumio/miniconda3"


in_files = [fq_file.path for fq_file in os.scandir("./input_data") if os.path.isfile(fq_file)]
accept_ext = ["fastq", "fq", "fasta", "fa", "fna"]
barcodes = [os.path.split(fpath)[-1].split(".")[0] for fpath in in_files if os.path.split(fpath)[-1].split(".")[1] in accept_ext]
print(barcodes)

rule all:
    input:
        expand("results/{barcode}_corr/{barcode}.correctedReads.fasta", barcode=barcodes),
        expand("results/{barcode}_polish/medaka/consensus.fasta", barcode=barcodes),
        expand("results/{barcode}_primertrim/{barcode}.fastq", barcode=barcodes),
        expand("results/{barcode}_spades_asm/raw_contigs.fasta", barcode=barcodes),
        expand("results/{barcode}_ragoo/ragoo_output/ragoo.fasta", barcode=barcodes)


rule intial_qc:
    input:
        "input_data/{barcode}.fastq"
    output:
        directory("results/{barcode}/qc/initial")
    log:
        "logs/{barcode}/{barcode}_initialQC.log"
    conda:
        "envs/nanoqc.yaml"
    shell:
        "nanoQC {input} -o {output}"


rule porechop_adapter_barcode_trimming:
    input:
        fastq_in="input_data/{barcode}.fastq"
    output:
        out_dir=directory("results/{barcode}_abtrim"),
        out_file="results/{barcode}_abtrim/{barcode}.fastq"
    conda:
        "envs/porechop.yaml"
    threads: 2
    shell:
        "porechop -i {input.fastq_in} -o {output.out_file} --threads {threads} -v 0"


rule customize_primer_porechop:
    # This rule needs to be further edited in order to allow use not only of v3 ARTIC primers.
    # However, first it has to be clarified how the primer-set and version are specified (sample-sheet, commandline-flag...).
    output:
        "workflow/report/replacement_notice.txt"
    conda:
        "envs/primechop.yaml"
    shell:
        """
        cp ./resources/ARTIC_v3_adapters.py $CONDA_PREFIX/lib/python3.6/site-packages/porechop/adapters.py
        touch workflow/report/replacement_notice.txt
        echo "replaced adpaters in adapter.py file with ARTICv3 primers" > workflow/report/replacement_notice.txt
        """


rule porechop_primer_trimming:
    input:
        fastq_in="results/{barcode}_abtrim/{barcode}.fastq",
        repl_flag="workflow/report/replacement_notice.txt"
    output:
        "results/{barcode}_primertrim/{barcode}.fastq"
    conda:
        "envs/primechop.yaml"
    threads: 2
    shell:
        """
        porechop -i {input.fastq_in} -o {output} --no_split --end_size 35 --extra_end_trim 0 --threads {threads} -v 0
        rm workflow/report/replacement_notice.txt
        """


rule nanofilt:
    input:
        "results/{barcode}_primertrim/{barcode}.fastq"
    output:
        "results/{barcode}/trim-filt/{barcode}_tf.fastq"
    log:
        "logs/{barcode}/{barcode}_nanofilt.log"
    conda:
        "envs/nanofilt.yaml"
    shell:
        "NanoFilt {input} -q 10 --maxlength 500 > {output}"


rule post_trimfilt_qc:
    input:
        "results/{barcode}/trim-filt/{barcode}_tf.fastq"
    output:
        directory("results/{barcode}/qc/post_trimfilt_qc")
    log:
        "logs/{barcode}/{barcode}_post_trimfilt_qc.log"
    conda:
        "envs/nanoqc.yaml"
    shell:
        "nanoQC {input} -o {output}"


rule convert2fasta:
    input:
        "results/{barcode}/trim-filt/{barcode}_tf.fastq"
    output:
        "results/{barcode}_fa/{barcode}_tf.fasta"
    conda:
        "envs/seqtk.yaml"
    shell:
        "seqtk seq -A  {input} > {output}"


rule medaka_polish_reference:
    input:
        in_file="results/{barcode}_fa/{barcode}_tf.fasta",
        reference = "resources/MN908947.3_SARS-CoV2_Wuhan-reference.fasta"
    output:
        outdir=directory("results/{barcode}_polish/medaka"),
        outfile="results/{barcode}_polish/medaka/consensus.fasta"
    conda:
        "envs/medaka.yaml"
    threads: 4
    shell:
        "medaka_consensus -v -i {input.in_file} -o {output.outdir} -d {input.reference} -t {threads}"


rule canu_correct:
    input:
        "results/{barcode}_fa/{barcode}_tf.fasta"
    output:
        out_dir=directory("results/{barcode}_corr"),
        out_file="results/{barcode}_corr/{barcode}.correctedReads.fasta"
    conda:
        "envs/canu.yaml"
    threads:
        16
    params:
        concurrency = lambda w, threads: int(threads/ 4) 
    shell:
        # merylConcurrency={params.concurrency} merylThreads={threads} \ has no effect; according to canu documentation only one thread is used, although terminal output states otherwise
        # the hap stage should be irrelevant, since no phasing is performed
        # useGrid ist set to "False" for now for safety reasons, because Canu will submit all jobs by itself to a grid if detected, circumventing the control of snakemake, which is undesireable.
        # To not impede scalability the useGrid parameter could be set to "remote" and maybe control can remain with the workflow engine, but that needs to be tested.
        """
        canu -correct -nanopore {input} -p {wildcards.barcode} -d {output.out_dir} genomeSize=30k minOverlapLength=10 minReadLength=200 useGrid=false \
        corMMapMerSize=10 corOutCoverage=50000 corMinCoverage=0 maxInputCoverage=20000 \
        corOverlapper=minimap utgOverlapper=minimap obtOverlapper=minimap \
        corConcurrency={params.concurrency} \
        cormhapConcurrency={params.concurrency} cormhapThreads={params.concurrency} \
        cormmapConcurrency={params.concurrency} cormmapThreads={params.concurrency} \
        obtmmapConcurrency={params.concurrency} obtmmapThreads={params.concurrency} \
        utgmmapConcurrency={params.concurrency} utgmmapThreads={params.concurrency} \
        redConcurrency={params.concurrency} redThreads={params.concurrency} \
        ovbConcurrency={params.concurrency} \
        ovsConcurrency={params.concurrency} \
        oeaConcurrency={params.concurrency}
        gzip -d results/{wildcards.barcode}_corr/{wildcards.barcode}.correctedReads.fasta.gz
        """

rule spades_assemble:
    input:
       "results/{barcode}_corr/{barcode}.correctedReads.fasta"
    output:
        outdir = directory("results/{barcode}_spades_asm"),
        outfile = "results/{barcode}_spades_asm/raw_contigs.fasta"
    conda:
        "envs/spades.yaml"
    threads: 6
    shell:
        "spades.py --corona -s {input} -o {output.outdir}"


rule ragoo:
    input:
        tigs_in = "results/{barcode}_spades_asm/raw_contigs.fasta",
        ref = "resources/MN908947.3_SARS-CoV2_Wuhan-reference.fasta"
    output:
        "results/{barcode}_ragoo/ragoo_output/ragoo.fasta"
    conda:
        "envs/ragoo.yaml"
    shell:
        "mkdir -p results/{wildcards.barcode}_ragoo && cd results/{wildcards.barcode}_ragoo && ragoo.py ../../{input.tigs_in} ../../{input.ref}"


# rule cleanup:
#     input:
#         input=[f"results/{barcode}_asm/{barcode}.canu_asm.fasta.gz" for barcode in barcodes]
#     shell:
#         """
#         rm workflow/report/replacement_notice.txt
#         """
        